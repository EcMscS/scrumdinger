//
//  SpeechService.swift
//
//  Created by James Sedlacek on 2/17/25.
//

import AVFoundation
import Foundation
import Speech
import SwiftUI

/// A service that manages speech recognition using SFSpeechRecognizer.
public final class SpeechService: SpeechServiceProtocol, @unchecked Sendable {
    private var accumulatedText: String = ""
    private var audioEngine: AVAudioEngine?
    private var request: SFSpeechAudioBufferRecognitionRequest?
    private var task: SFSpeechRecognitionTask?
    private let recognizer: SFSpeechRecognizer?
    private var continuationHandler: AsyncThrowingStream<String, Error>.Continuation?

    public init(localeIdentifier: String = Locale.current.identifier) {
        print("ğŸ¤ Initializing SpeechService...")
        print("ğŸ“ Using locale: \(localeIdentifier)")
        recognizer = SFSpeechRecognizer(locale: Locale(identifier: localeIdentifier))
        print(recognizer != nil ? "âœ… SpeechRecognizer created" : "âŒ Failed to create SpeechRecognizer")
    }

    /// Request necessary permissions for speech recognition.
    @MainActor public func requestPermissions() async throws(SpeechServiceError) {
        print("ğŸ” Requesting speech recognition permissions...")

        guard let recognizer else {
            print("âŒ SpeechRecognizer not initialized")
            throw .initializationFailed
        }

        print("ğŸ¤ Checking speech recognition authorization...")
        let authStatus = await SFSpeechRecognizer.hasAuthorizationToRecognize()
        print("ğŸ“Š Authorization status: \(authStatus)")
        guard authStatus else {
            print("âŒ Not authorized to recognize speech")
            throw .notAuthorizedToRecognize
        }
        print("âœ… Speech recognition authorized")

        print("ğŸ™ï¸ Checking microphone permission...")
        let recordPermission = await AVAudioSession.sharedInstance().hasPermissionToRecord()
        print("ğŸ“Š Record permission: \(recordPermission)")
        guard recordPermission else {
            print("âŒ Not permitted to record audio")
            throw .notPermittedToRecord
        }
        print("âœ… Microphone access granted")

        print("ğŸ” Checking recognizer availability...")
        print("ğŸ“Š Recognizer available: \(recognizer.isAvailable)")
        guard recognizer.isAvailable else {
            print("âŒ Speech recognizer unavailable")
            throw .recognizerUnavailable
        }
    }

    /// Start recording and transcribing speech.
    @MainActor public func startRecording() throws(SpeechServiceError) -> AsyncThrowingStream<String, Error> {
        print("ğŸ¤ Starting speech recording...")

        guard let recognizer, recognizer.isAvailable else {
            print("âŒ Speech recognizer unavailable")
            throw .recognizerUnavailable
        }

        print("ğŸ”„ Stopping any existing recording...")
        stopRecording()

        print("ğŸŒŠ Creating transcription stream...")
        return createTranscriptionStream()
    }

    @MainActor
    private func createTranscriptionStream() -> AsyncThrowingStream<String, Error> {
        print("ğŸ”„ Creating transcription stream...")
        return AsyncThrowingStream { continuation in
            print("ğŸ“ Setting up continuation handler...")
            self.continuationHandler = continuation

            Task {
                do {
                    print("âš™ï¸ Configuring audio session...")
                    let (engine, request) = try Self.configureAudioSession()
                    self.audioEngine = engine
                    self.request = request

                    print("ğŸ¯ Creating recognition task...")
                    task = recognizer?.recognitionTask(with: request) { [weak self] result, error in
                        print("ğŸ“ Recognition callback - hasResult: \(result != nil), hasError: \(error != nil)")
                        guard let self else {
                            print("âš ï¸ Self is nil in recognition callback")
                            return
                        }

                        if let error {
                            print("âŒ Recognition error: \(error)")
                            continuation.finish(throwing: error)
                            print("ğŸ›‘ Stopping recording due to error")
                            self.stopRecording()
                            return
                        }

                        if let result {
                            let newText = result.bestTranscription.formattedString
                            print("ğŸ“ New transcription: \(newText)")
                            continuation.yield(self.accumulatedText + newText)

                            if result.isFinal {
                                print("âœ… Final result received")
                                self.accumulatedText += newText + " "
                                print("ğŸ”„ Stopping recording after final result")
                                self.stopRecording()
                            }
                        }
                    }

                    print("âœ… Recording started successfully")

                } catch {
                    print("âŒ Stream setup error: \(error)")
                    continuation.finish(throwing: error)
                    print("ğŸ›‘ Stopping recording due to setup error")
                    self.stopRecording()
                }
            }
        }
    }

    private static func configureAudioSession() throws -> (AVAudioEngine, SFSpeechAudioBufferRecognitionRequest) {
        print("ğŸ”„ Setting up audio session...")
        let audioEngine = AVAudioEngine()
        let request = SFSpeechAudioBufferRecognitionRequest()
        request.shouldReportPartialResults = true
        request.taskHint = .dictation
        request.addsPunctuation = true

        print("âš™ï¸ Configuring audio session...")
        let audioSession = AVAudioSession.sharedInstance()
        do {
            print("ğŸ”Š Setting audio session category...")
            try audioSession.setCategory(.playAndRecord, mode: .measurement, options: .duckOthers)
            print("ğŸ”Š Activating audio session...")
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            print("âŒ Audio session configuration error: \(error)")
            throw error
        }

        print("ğŸ™ï¸ Setting up audio input...")
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)
        print("ğŸ“Š Recording format: \(recordingFormat)")

        print("ğŸ“ Installing audio tap...")
        inputNode.installTap(
            onBus: 0,
            bufferSize: 1024,
            format: recordingFormat
        ) { [weak request] buffer, _ in
            print("ğŸ”„ Processing audio buffer...")
            request?.append(buffer)
        }

        print("ğŸ”„ Starting audio engine...")
        audioEngine.prepare()
        do {
            try audioEngine.start()
            print("âœ… Audio engine started successfully")
        } catch {
            print("âŒ Audio engine start error: \(error)")
            throw error
        }

        return (audioEngine, request)
    }

    /// Stop recording and transcribing speech.
    public func stopRecording() {
        print("ğŸ›‘ Stopping speech recording...")

        if let task = task {
            print("ğŸ”„ Cancelling recognition task...")
            task.cancel()
            self.task = nil
        }

        if let engine = audioEngine {
            print("ğŸ”„ Stopping audio engine...")
            engine.stop()
            engine.inputNode.removeTap(onBus: 0)
            self.audioEngine = nil
        }

        print("ğŸ§¹ Cleaning up request...")
        request = nil

        if let handler = continuationHandler {
            print("ğŸ”„ Finishing continuation handler...")
            handler.finish()
            continuationHandler = nil
        }

        print("ğŸ”Š Deactivating audio session...")
        do {
            try AVAudioSession.sharedInstance().setActive(false, options: .notifyOthersOnDeactivation)
        } catch {
            print("âš ï¸ Error deactivating audio session: \(error)")
        }

        print("âœ… Recording stopped successfully")
    }
}
